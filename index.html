<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Our new approach LMDpp enhanced a two-stage LMD pipeline to improve object spatial relationships, spacing, and numeracy in image generation through prompting. We also introduced the SON-1K benchmark, offering more complex challenges in spatial reasoning, numeracy, and natural language than existing works.">
  <meta name="keywords" content="LMDpp, compositional text-to-image benchmark, SON-1K, SON">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SON: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models Guided Layouts</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="icon" href="https://datascience.ucsd.edu/wp-content/uploads/fbrfg/favicon-32x32.png">

  <link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  

  <!-- juxtapose -->
  <script src="static/js/juxtapose.js"></script>

  <!-- <script src="./static/js/jquery-3.2.1.min.js" type="text/javascript"></script>
<script src="./static/js/jquery.event.move.js" type="text/javascript"></script>
<script src="./static/js/jquery.twentytwenty.js" type="text/javascript"></script>
<link rel="stylesheet" href="./static/css/twentytwenty.css" type="text/css" media="screen" /> -->

</head>


<body>

<!-- paper title and author -->
<section class="section">
  <!-- <div class="hero-body"> -->
    <div class="container is-max-desktop no_max_width">
      <div class="columns is-centered">
        <div class="column has-text-centered is-four-fifths">
          <h1 class="title is-1 publication-title">
            ðŸ’¡ <span class="rainbow_text_animated">SON</span>
            : Enhancing Prompt Understanding of Diffusion Models with Large Language Models Guided Layouts
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://weiyueli7.github.io">
                <span class="fancy_text_color">Weiyue Li</span>
              </a>,
            </span>
            <span class="author-block">
              <a href="https://jerryli1019.github.io">
                <span class="fancy_text_color">Yi Li</span>
              </a>,</span>
            <span class="author-block">
              <a href="https://dpwxy.github.io/xiaoyuewang15.github.io/">
                <span class="fancy_text_color">Xiaoyue Wang</span>
              </a>,
            </span>
            <span class="author-block">
              <a href="https://cseweb.ucsd.edu/~haozhang/">
                <span class="fancy_text_color">Hao Zhang</span>
              </a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of California, San Diego</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="font-size: 70%;"><i>2024 Data Science Senior Capstone at UC San Diego.</i></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/weiyueli7/SON"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Data Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg xmlns="http://www.w3.org/2000/svg" height="16" width="14" viewBox="0 0 448 512"><!--!Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2023 Fonticons, Inc.--><path fill="#ffffff" d="M448 80v48c0 44.2-100.3 80-224 80S0 172.2 0 128V80C0 35.8 100.3 0 224 0S448 35.8 448 80zM393.2 214.7c20.8-7.4 39.9-16.9 54.8-28.6V288c0 44.2-100.3 80-224 80S0 332.2 0 288V186.1c14.9 11.8 34 21.2 54.8 28.6C99.7 230.7 159.5 240 224 240s124.3-9.3 169.2-25.3zM0 346.1c14.9 11.8 34 21.2 54.8 28.6C99.7 390.7 159.5 400 224 400s124.3-9.3 169.2-25.3c20.8-7.4 39.9-16.9 54.8-28.6V432c0 44.2-100.3 80-224 80S0 476.2 0 432V346.1z"/></svg>
                  </span>
                  <span>Data</span>
                </a>
              </span>
            </div>

          </div>


        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="subtitle has-text-centered">
            A <span class="fancy_text_color">
              compositional text-to-image generation
            </span> benchmark and a new approach of <b>Language Model-Guided Diffusion++ (LMDpp)</b>.
          </h2>
        </div>
      </div>
      <div class="has-text-centered">
        <img src="./static/images/showcase.png" width="1500">
      </div>


    </div>
</section>



<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <!-- abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <span class="fancy_text_color">Abstract</span>
        </h2>
  
        <div style="font-size: 20px; margin-bottom: 1em;">
          <p>
            The recent development of text-to-image (T2I) models has unlocked numerous possibilities for content creation, particularly by offering inspiration to designers. However, current approaches often face challenges in accurately following prompts to generate images. These challenges include arranging non-overlapping objects in various spatial relationships and producing the correct number of desired objects, both of which are crucial for many design tasks. We introduce <strong>S</strong>patial-<strong>O</strong>verlap-<strong>N</strong>umeracy-1K (<strong>SON-1K</strong>), a comprehensive benchmark for text-to-image generation. This benchmark comprises 1,000 complex prompts spanning three subtasks: spatial relationships, numeracy counts, and complex natural prompts. Alongside the benchmark, we propose several evaluation metrics to assess compliance with the prompts comprehensively. We also propose a new approach, the <strong>L</strong>anguage <strong>M</strong>odel-Guided <strong>D</strong>iffusion<strong>++</strong> (LMDpp)</strong>, enhancing the performance of the novel two-stage Large Language Model (LLM)-grounded diffusion model pipeline (LMD). We report experimental results of previous major T2I models and our enhanced LMDpp, along with its baseline on SON-1K, and provide an analysis of our new metrics.
          </p>
        </div>
        <h2 class="title is-3" style="margin-top: 2em;">
          <span class="fancy_text_color">Benchmark</span>
        </h2>
        <div class="has-text-centered">
          <img src="./static/images/dataset.png" width="1000">
        </div>
  
        <h2 class="subtitle has-text-centered" style="font-size: 19px; margin-top: 1em;">
          <b>Overview of SON-1K</b>, a comprehensive benchmark for text-to-image generation.
          </h2>
      </div>
    </div>

    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: 1em;">
          <span class="fancy_text_color">
            <b>An overview of the Language Model-Guided Diffusion++ (LMDpp) pipeline</b>
          </span>
        </h2>
        <div class="has-text-centered">
          <img src="./static/images/inference.png" width="1000">
        </div>
        <div>
          <p style="font-size: 20px;margin-left:5em;margin-right:5em;margin-top:1em">In stage one, our pipeline takes the scene description from the user and outputs the image layout based on our refined prompt, incorporated with mathematical relationships and chain of thought techniques. In stage two, the stable diffusion model generates the final image guided by the layout-grounded controller.</p>
        </div>

        </br></br>
      </div>
    </div>

  </div>
  
</section>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <span class="fancy_text_color">
            <b>Performance of models on the SON-1k Benchmark</b>
          </span>
        </h2>

        <div class="title is-4" style="margin-bottom: 1em;">
          <b>The Stage 1 Spatial and Numeracy Task Improvements</b>
        </div>
        <div class="has-text-centered">
          <img src="./static/images/stage_1_improvement.png" width="1000">
          <p style="font-size: 20px;margin-left:5em;margin-right:5em;margin-top:1em">Comparison of numeracy and spatial accuracy among different templates of prompt</p>
        </div>
        <br>
        <div class="title is-4" style="margin-bottom: 1em; margin-top: 1em;">
          <b>The Results Tables on Stage 1 and Stage 2 Performance</b>
        </div>
        <div class="has-text-centered">
          <img src="./static/images/spatial_result.png" width="1000">
          <p style="font-size: 20px; margin-left:5em;margin-right:5em;margin-bottom:3em">Table 1: Evaluation results for Spatial Tasks. % Overlap (S1) indicates the overlap rate for the layout image generated by the LLM in stage one. Spa-Acc (S1) indicates the spatial accuracy for stage one. SON indicates the values measured by our metric SON.</p>
        </div>
        <div class="has-text-centered">
          <img src="./static/images/numeracy_result.png" width="1000">
          <p style="font-size: 20px;margin-left:5em;margin-right:5em;margin-bottom:3em">Table 2: Evaluation results for Numeracy Tasks. Num-Recall (S1) indicates the numeracy recall score for stage one. Num-Acc (S1) indicates the numeracy accuracy for stage one.</p>
        </div>
        <div class="has-text-centered">
          <img src="./static/images/complex_result.png" width="1000">
          <p style="font-size: 20px;margin-left:5em;margin-right:5em;margin-bottom:3em">Table 3: Evaluation results for Complex Prompts. EMR (S2) indicates the EMR score of the final image generated by the diffusion model in stage two.</p>
        </div>
        <div class="has-text-centered">
          <img src="./static/images/further_result.png" width="1000">
          <p style="font-size: 20px;margin-left:5em;margin-right:5em;margin-bottom:3em">Table 4: Further Evaluation Results. Spa-Acc (S2) indicates the spatial accuracy for stage two. % Overlap (S2) indicates the overlap rate for stage two.</p>
        </div>
        <!-- <div class="has-text-centered">
          <img src="static/images/table1.jpg">
        </div> -->
      </div>
    </div>


<footer class="footer" style="padding-bottom: 1.5em; padding-top: 1.5em;">
  <div class="container">
    <div class="content has-text-centered">
      <span>This website is adaptecd from <a href="https://mlpc-ucsd.github.io/TokenCompose/">TokenCompose</a> and <a href="https://nerfies.github.io">Nerfies</a>.</span>
    </div>
  </div>
</footer>
</body>
<script src="./static/js/index.js"></script>
</html>
